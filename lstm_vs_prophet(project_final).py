# -*- coding: utf-8 -*-
"""LSTM VS PROPHET(PROJECT_FINAL).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ilUMy1UpRsPOJ4b9c7TNoDFt84l9p3hM
"""

!pip install  ipywidgets

import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from prophet import Prophet
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
import plotly
from prophet.plot import plot_plotly
from prophet.plot import plot_components_plotly,plot_cross_validation_metric
from prophet.diagnostics import performance_metrics,cross_validation

# Load the stock price data
data = pd.read_csv('HDFC.csv')

# Preprocess the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))

data

data.info()

data.describe()

data.isnull().sum()

data[['Date','Close']]

data[['Date','Close']].describe()

data.plot(x='Date',y='Close', figsize=(10,6))

plt.scatter(x=data['Date'],y=data['Close'],c='orange', s=5)

dataplot= sns.heatmap(data.corr(),annot=True)

# Split the data into training and testing datasets
X = scaled_data[:-1]  # Input sequence
y = scaled_data[1:]   # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)

X

y

# Reshape the data for LSTM input (samples, time steps, features)
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(LSTM(units=50))
model.add(Dense(units=1))

# Compile and train the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10, batch_size=32)

from statsmodels.tools.eval_measures import rmse

# Make predictions
predictions = model.predict(X_test)

# Scale the predictions back to the original range
predictions = scaler.inverse_transform(predictions)
y_test = scaler.inverse_transform(y_test)

# Calculate R2 score
r2 = r2_score(y_test, predictions)
print("R2 Score:", r2)
plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual')
plt.plot(predictions, label='Prediction')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Actual vs Prediction')
plt.legend()
plt.show()

print("Root Mean Squred Error between actual and predicted values: ",rmse(predictions,y_test))
print("Mean Value of Test Dataset: ", y_test.mean())

predictions

data

data['Date']=pd.to_datetime(data['Date'])
train_size = int(len(data)-365)
train_data = data.iloc[:train_size]
test_data = data.iloc[train_size:]
prophet_data = data[['Date','Close']].rename(columns={'Date': 'ds', 'Close': 'y'})
# Train the Prophet model
prophet_model = Prophet()
prophet_model.fit(prophet_data[:train_size])

# Make predictions with the Prophet model
future = prophet_model.make_future_dataframe(periods=len(test_data))
forecast = prophet_model.predict(future)
'''prophet_predictions = prophet_predictions['yhat'].tail(len(test_data)).values'''

df_cv = cross_validation(prophet_model, initial='730 days', period='180 days', horizon = '365 days')
df_cv.head()

df_cv2=performance_metrics(df_cv)
df_cv2

fig = plot_cross_validation_metric(df_cv, metric='rmse')
fig.show()

forecast.tail

forecast[['ds','yhat','yhat_lower','yhat_upper']].tail()

test_data

fig = plot_plotly(prophet_model,forecast)
fig.show()

fig = plot_components_plotly(prophet_model,forecast)
fig.show()

"""#**EVALUATING MODEL**"""

from statsmodels.tools.eval_measures import rmse

predictions_prophet=forecast.iloc[-365:]['yhat']

print("Root Mean Squred Error between actual and predicted values: ",rmse(predictions_prophet,test_data['Close']))
print("Mean Value of Test Dataset: ", test_data['Close'].mean())

data

plt.figure(figsize=(12, 6))
plt.plot(data['Close'], label='True Values')
plt.plot(forecast['yhat'],label='Prophet Predictions')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Prophet Model: True vs Predicted')
plt.legend()
plt.show()

!pip install pmdarima''

'''import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from pmdarima import auto_arima

# Load the stock price data
data = pd.read_csv('HDFC.csv')

# Preprocess the data
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)
data.sort_index(inplace=True)

# Perform AutoARIMA for time series forecasting
model = auto_arima(data['Close'], trace=True, suppress_warnings=True)

# Make predictions
predictions = model.predict(n_periods=len(data))

# Calculate R2 score
r2 = r2_score(data['Close'], predictions)
print("R2 Score:", r2)

# Plot actual vs prediction
plt.figure(figsize=(12, 6))
plt.plot(data.index, data['Close'], label='Actual')
plt.plot(data.index, predictions, label='Prediction')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Actual vs Prediction')
plt.legend()
plt.show()'''